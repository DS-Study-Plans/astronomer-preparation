Executor helps to scale and manage different queue strategies on the execution of tasks

There are several types:

* **Sequential Executor:** Allows to execute the tasks sequentially, no parallelization.
  It's only recommended for development of experimental use
    
* **Local Executor:** Allows executing multiple tasks at the same time in one machine.
To set it up, the database metadata must be change for example to postgres and change
  the parameter of "executor" in the airflow.cfg file

* **Celery Executor:** Execute the tasks in celery clusters to distribute the tasks on
multiple machines. It requires a queue to orchestrate as rabbit or redis.
  In each machine, a celery worker must be setup

To enable several executions at the time, there are some parameters that must be set:

* **parallelism:** Defines the maximum number of task that can be executed in the entire
airflow instance
* **dag_concurrency:** Number of task for a given dag that can be executed in parallel across
all the dag runs
  
* **max_active_runs_per_dag:** How many dag runs can be run at the same time for a given
dag run
  
The previous parameters are set for the entire airflow instance, but if needed to set only
to specific dags, tasks, etc. It can be used some classes parameters:

* **max_active_runs**: LImit the number of dag runs that run in parallel for a specific dag
* **concurrency:** Max number of tasks that can be run at the time for all the dag runs of a specific dag
